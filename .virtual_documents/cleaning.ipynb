


# Import libs
import pandas as pd
import numpy as np





# Read database 1 
data_f1 = pd.read_csv("data_f1.csv")


# General data_f1 view
data_f1.head(10)


# Review data_f1 information 
data_f1.shape


# Review data_f1 columns 
data_f1.columns


# Review data_f1 general information
data_f1.info()


# Review the data and how many rows have missing information in each columns
data_f1.isna().sum()





# Make a copy called dirty_dataf1
dirty_dataf1 = data_f1


# Introduce spelling errors in 'Airline' column in dirty_dataf1
dirty_dataf1.loc[dirty_dataf1.sample(frac=0.1).index, 'Airline'] = 'Airlne'


# Review changes in dirty_dataf1
dirty_dataf1.head(10)


# Change 'Price' column to strings
dirty_dataf1['Price'] = dirty_dataf1['Price'].astype(str)


# Review data_f1 general information
dirty_dataf1.info()


# Introduce incorrect values in 'Total_Stops'
dirty_dataf1.loc[dirty_dataf1.sample(frac=0.1).index, 'Total_Stops'] = -1


# Review changes in dirty_dataf1
dirty_dataf1.head(10)


# Introduce duplicates to dirty_dataf1
dirty_dataf1 = pd.concat([dirty_dataf1, dirty_dataf1.sample(frac=0.1)])


# Count the number of duplicate rows
dirty_dataf1.duplicated().sum()


# Missnamed two columns
dirty_dataf1 = dirty_dataf1.rename(columns={'Route': 'Rute', 'Source': 'Sourke'})


# Review changes in dirty_dataf1
dirty_dataf1.head(5)





# Make a copy of dirty_dataf1 to clean
clean_dataf1 = dirty_dataf1


# Correct spelling errors in Airline column
clean_dataf1['Airline'] = clean_dataf1['Airline'].replace('Airlne', 'Airline')


# Review changes in clean_dataf1
clean_dataf1.head(10)


# Change 'Price' column to integer
clean_dataf1['Price'] = clean_dataf1['Price'].astype(int)


# Review clean_dataf1 general information
clean_dataf1.info()


# Correct negative values in Total_Stops
# Replace -1 with 'non-stop' in the 'Total_Stops' column
clean_dataf1['Total_Stops'] = clean_dataf1['Total_Stops'].replace(-1, 'non-stop')


# Review changes in clean_dataf1
clean_dataf1.head(10)


# Drop duplicates from clean_dataf1
clean_dataf1.drop_duplicates()


# Review changes
clean_dataf1.shape


# Properly name the columns
clean_dataf1 = clean_dataf1.rename(columns={'Rute': 'Route', 'Sourke': 'Source'})


# General clean_dataf1 view
clean_dataf1.head(3)


# Review the data and how many rows have missing information in each columns
clean_dataf1.isna().sum()


# Fill missing values of Total_Stops with the mode

# Calculate the mode of the Total_Stops
mode_t = clean_dataf1['Total_Stops'].mode()[0]

# Fill missing values with the mode
clean_dataf1['Total_Stops'] = clean_dataf1['Total_Stops'].fillna(mode_t)


# Review the data and how many rows have missing information in each columns
clean_dataf1.isna().sum()


# Fill missing values of Route with the mode

# Calculate the mode of the Route
mode_r = clean_dataf1['Route'].mode()[0]

# Fill missing values with the mode
clean_dataf1['Route'] = clean_dataf1['Route'].fillna(mode_r)


# Review the data and how many rows have missing information in each columns
clean_dataf1.isna().sum()


# Save the cleaned dataset 1 ('clean_dataf1')
clean_dataf1.to_csv('clean_dataf1.csv', index=False)





# Read database 2
data_f2 = pd.read_csv("data_f2.csv")


# General data_f2 view
data_f2.head(3)


# Review data_f2 general information
data_f2.info()


# Review the data and how many rows have missing information in each columns
data_f2.isna().sum()





# Make a copy called dirty_dataf2
dirty_dataf2 = data_f2


# Add redundant columns ('Duration') with changed type 
dirty_dataf2['Duration'] = dirty_dataf2['duration'].astype(int)


# General dirty_dataf2 view
dirty_dataf2.head(3)


# Add extra whitespace to airline
dirty_dataf2['airline'] = dirty_dataf2['airline'].apply(lambda x: x + '   ')


# General dirty_dataf2 view
dirty_dataf2.head(3)


# Add special characters to flight
dirty_dataf2['flight'] = dirty_dataf2['flight'].apply(lambda x: x + '@!')


# General dirty_dataf2 view
dirty_dataf2.head(3)





# Make a copy of dirty_dataf2 to clean
clean_dataf2 = dirty_dataf2


# Remove redundant column Duration
clean_dataf2 = clean_dataf2.drop(columns=['Duration'])


# General clean_dataf2 view
clean_dataf2.head(3)


# Eliminate extra whitespace from airline
clean_dataf2['airline'] = clean_dataf2['airline'].str.strip()


# General cleaned_dataf2 view
clean_dataf2.head(3)


# Remove special characters from flight
clean_dataf2['flight'] = clean_dataf2['flight'].str.replace('@!', '', regex=False)


# General cleaned_dataf2 view
clean_dataf2.head(3)


# Drop column Unnamed: 0
clean_dataf2 = clean_dataf2.drop(columns=['Unnamed: 0'])


# Review clean_dataf2 general information
clean_dataf2.info()


# Review the data and how many rows have missing information in each columns
clean_dataf2.isna().sum()


# Save the cleaned dataset 2 ('cleaned_dataf2')
clean_dataf2.to_csv('clean_dataf2.csv', index=False)



